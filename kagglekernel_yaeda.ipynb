{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d25efdd1d4a98fb6dd8bac9713e79c4a9e47d6b"
   },
   "source": [
    "## Overview\n",
    "\n",
    "The purpose of this kernel is to take a look at the data, come up with some insights, and attempt to create a predictive model or two. So let's get started!\n",
    "\n",
    "## Packages\n",
    "\n",
    "First, let's load a few useful Python packages. This section will keep growing in subsequent versions of this EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "#import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import describe\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a0d066154bede603d868fab8a177b6d354308c3"
   },
   "source": [
    "Now let us look at the input folder. Here we find all the relevant files for this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "364e9aeaeab5fe13cd4ad4b4af65ebe25c60c0a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv', 'test.csv.zip', 'train.csv.zip', 'sample_submission.csv.zip', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "PATH = \"data\"\n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab7d6e3f8f154265b496eda020d96d32c841840d"
   },
   "source": [
    "We see that the input folder only contains three files ```train.csv```, ```test.csv```, and ```sample_submission.csv```. It seems that for this competition we don't have to do any complicated combination and mergers of files.\n",
    "\n",
    "Now let's import and take a glimpse at these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d6aaf2</td>\n",
       "      <td>38000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fbd867</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0027d6b71</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028cbf45</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002a68644</td>\n",
       "      <td>14400000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4993 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      target  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  \\\n",
       "0  000d6aaf2  38000000.0        0.0          0        0.0          0   \n",
       "1  000fbd867    600000.0        0.0          0        0.0          0   \n",
       "2  0027d6b71  10000000.0        0.0          0        0.0          0   \n",
       "3  0028cbf45   2000000.0        0.0          0        0.0          0   \n",
       "4  002a68644  14400000.0        0.0          0        0.0          0   \n",
       "\n",
       "   2f0771a37  30347e683  d08d1fbe3  6ee66e115    ...      3ecc09859  \\\n",
       "0          0          0          0          0    ...            0.0   \n",
       "1          0          0          0          0    ...            0.0   \n",
       "2          0          0          0          0    ...            0.0   \n",
       "3          0          0          0          0    ...            0.0   \n",
       "4          0          0          0          0    ...            0.0   \n",
       "\n",
       "   9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "0        0.0        0.0          0          0          0          0   \n",
       "1        0.0        0.0          0          0          0          0   \n",
       "2        0.0        0.0          0          0          0          0   \n",
       "3        0.0        0.0          0          0          0          0   \n",
       "4        0.0        0.0          0          0          0          0   \n",
       "\n",
       "   fb36b89d9  7e293fbaf  9fc776466  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  \n",
       "\n",
       "[5 rows x 4993 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "289c27a69e66bf37a0253e1377747984cc3d6a25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 4993)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "80c5ea30234a44f367859a8091eaa5fbfc2f1d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4459 entries, 0 to 4458\n",
      "Columns: 4993 entries, ID to 9fc776466\n",
      "dtypes: float64(1845), int64(3147), object(1)\n",
      "memory usage: 169.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "f0bc6cc7fe7015081088285aada122fac4a5a37b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c50d9055156062b435f0dff064d5c00a08e89e22"
   },
   "source": [
    "A few things immediately stand out:\n",
    "\n",
    "1. As advertised, features are numeric and anonymized. \n",
    "2. Features seem sparse. We'll have to investigate this further. \n",
    "3. There are a LOT of features! Almost 5000! And they outnumber the number of rows in the training set!\n",
    "4. There are less than 5000 training rows. In fact, there are fewer rows than columns, which means we'll have to invest a lot of effort into feature selection / feature engineering. \n",
    "5. The memory size of the train dataset is fairly large - 170 MB, which is to be expected. \n",
    "6. Pandas is treating 1845 features as float, and 3147 as integer. It is possible that some of those int features are one-hot-encoded or label-encoded categorical variables. We'll have to investigate this later, and possibly do some reverse-engineering. :)\n",
    "7. There doesn't appear to be any missing values in the train set. This is, IMHO, overall a good thing, although a lot of times there is some signal in the missing values that's valuable and worth exploring. \n",
    "\n",
    "This is going to be a very, very, interesting competition. :)\n",
    "\n",
    "Now let's take a look at the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "5700f9315f65a472e26d8e9f87f232dabcf9a72c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000137c73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00021489f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d7953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00056a333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00056d8eb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  \\\n",
       "0  000137c73        0.0        0.0        0.0        0.0        0.0   \n",
       "1  00021489f        0.0        0.0        0.0        0.0        0.0   \n",
       "2  0004d7953        0.0        0.0        0.0        0.0        0.0   \n",
       "3  00056a333        0.0        0.0        0.0        0.0        0.0   \n",
       "4  00056d8eb        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   30347e683  d08d1fbe3  6ee66e115  20aa07010    ...      3ecc09859  \\\n",
       "0        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "1        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "2        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "3        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "4        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "\n",
       "   9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   fb36b89d9  7e293fbaf  9fc776466  \n",
       "0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0  \n",
       "2        0.0        0.0        0.0  \n",
       "3        0.0        0.0        0.0  \n",
       "4        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 4992 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(PATH, 'test.csv'))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "b91ebc5a68adad1f478cf99953110412723e9dc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49343, 4992)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ee5d6807a37212719669366fe977bb4b3d079cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49343 entries, 0 to 49342\n",
      "Columns: 4992 entries, ID to 9fc776466\n",
      "dtypes: float64(4991), object(1)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "923e79dfb4670a4addbc5865674ad93b53fc8241"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "542d068e3ebf543ec365d5958b383f9f73d6f28b"
   },
   "source": [
    "Here we see that the number of features in the test set (4992) matches the number in the train set. Sanity check is always a good thing, and at leas at this level, hte Kaggle people did not mess things up.\n",
    "\n",
    "According to Pandas, there are no ```int``` values in the test set. Now I'm really curious about those ... \n",
    "\n",
    "There also doesn't seem to be any missing values in the test set. \n",
    "\n",
    "We also see that the number of rows in the test set far surpasses the number of rows in the train set. Yes, a very *interesting* competition indeed ...\n",
    "\n",
    "\n",
    "\n",
    "Now let's see some basic descriptive statistics for the train and test dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "017b21d1c2f8101fc8e3764f410deebe68f19f62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4459.000000</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "      <td>4.459000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.944923e+06</td>\n",
       "      <td>1.465493e+04</td>\n",
       "      <td>1.390895e+03</td>\n",
       "      <td>2.672245e+04</td>\n",
       "      <td>4.530164e+03</td>\n",
       "      <td>2.640996e+04</td>\n",
       "      <td>3.070811e+04</td>\n",
       "      <td>1.686522e+04</td>\n",
       "      <td>4.669208e+03</td>\n",
       "      <td>2.569407e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.676057e+05</td>\n",
       "      <td>4.446239e+05</td>\n",
       "      <td>8.056219e+05</td>\n",
       "      <td>7.812966e+05</td>\n",
       "      <td>143.529939</td>\n",
       "      <td>1.213809e+05</td>\n",
       "      <td>3.573451e+04</td>\n",
       "      <td>3.123741e+05</td>\n",
       "      <td>9.219960e+04</td>\n",
       "      <td>2.279100e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.234312e+06</td>\n",
       "      <td>3.893298e+05</td>\n",
       "      <td>6.428302e+04</td>\n",
       "      <td>5.699652e+05</td>\n",
       "      <td>2.359124e+05</td>\n",
       "      <td>1.514730e+06</td>\n",
       "      <td>5.770590e+05</td>\n",
       "      <td>7.512756e+05</td>\n",
       "      <td>1.879449e+05</td>\n",
       "      <td>9.610183e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.068038e+06</td>\n",
       "      <td>4.428889e+06</td>\n",
       "      <td>4.513246e+06</td>\n",
       "      <td>6.839451e+06</td>\n",
       "      <td>9584.318507</td>\n",
       "      <td>4.720709e+06</td>\n",
       "      <td>1.614622e+06</td>\n",
       "      <td>4.318501e+06</td>\n",
       "      <td>1.635993e+06</td>\n",
       "      <td>1.811139e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.260000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>2.000000e+07</td>\n",
       "      <td>1.480000e+07</td>\n",
       "      <td>1.000000e+08</td>\n",
       "      <td>2.070800e+07</td>\n",
       "      <td>4.000000e+07</td>\n",
       "      <td>1.040000e+07</td>\n",
       "      <td>3.196120e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>7.600000e+07</td>\n",
       "      <td>1.235880e+08</td>\n",
       "      <td>1.300000e+08</td>\n",
       "      <td>1.444000e+08</td>\n",
       "      <td>640000.000000</td>\n",
       "      <td>3.013120e+08</td>\n",
       "      <td>1.064200e+08</td>\n",
       "      <td>1.400000e+08</td>\n",
       "      <td>6.176800e+07</td>\n",
       "      <td>4.320000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 4992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             target     48df886f9     0deb4b6a8     34b15f335     a8cb14b00  \\\n",
       "count  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean   5.944923e+06  1.465493e+04  1.390895e+03  2.672245e+04  4.530164e+03   \n",
       "std    8.234312e+06  3.893298e+05  6.428302e+04  5.699652e+05  2.359124e+05   \n",
       "min    3.000000e+04  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    6.000000e+05  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    2.260000e+06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    8.000000e+06  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    4.000000e+07  2.000000e+07  4.000000e+06  2.000000e+07  1.480000e+07   \n",
       "\n",
       "          2f0771a37     30347e683     d08d1fbe3     6ee66e115     20aa07010  \\\n",
       "count  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean   2.640996e+04  3.070811e+04  1.686522e+04  4.669208e+03  2.569407e+06   \n",
       "std    1.514730e+06  5.770590e+05  7.512756e+05  1.879449e+05  9.610183e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  6.000000e+05   \n",
       "max    1.000000e+08  2.070800e+07  4.000000e+07  1.040000e+07  3.196120e+08   \n",
       "\n",
       "           ...          3ecc09859     9281abeea     8675bec0b     3a13ed79a  \\\n",
       "count      ...       4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean       ...       4.676057e+05  4.446239e+05  8.056219e+05  7.812966e+05   \n",
       "std        ...       4.068038e+06  4.428889e+06  4.513246e+06  6.839451e+06   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max        ...       7.600000e+07  1.235880e+08  1.300000e+08  1.444000e+08   \n",
       "\n",
       "           f677d4d13     71b203550     137efaa80     fb36b89d9     7e293fbaf  \\\n",
       "count    4459.000000  4.459000e+03  4.459000e+03  4.459000e+03  4.459000e+03   \n",
       "mean      143.529939  1.213809e+05  3.573451e+04  3.123741e+05  9.219960e+04   \n",
       "std      9584.318507  4.720709e+06  1.614622e+06  4.318501e+06  1.635993e+06   \n",
       "min         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%         0.000000  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    640000.000000  3.013120e+08  1.064200e+08  1.400000e+08  6.176800e+07   \n",
       "\n",
       "          9fc776466  \n",
       "count  4.459000e+03  \n",
       "mean   2.279100e+05  \n",
       "std    1.811139e+06  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    4.320000e+07  \n",
       "\n",
       "[8 rows x 4992 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_describe = train_df.describe()\n",
    "train_df_describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b02009cd7d5d9c1078ad82e168a812063924a745"
   },
   "source": [
    "A few things to notice:\n",
    "\n",
    "1.  Target variable ranges over 4 orders of magnitude. (factor of 10,000)\n",
    "2. Most features have 0.0 for 75% - another indication that we are probably dealing with sparse data.\n",
    "3. Most features seem to have similarly wide spread of values as the target variable. Hmm, interesting ...\n",
    "4. The standard deviation for most features seems larger than the feature mean. \n",
    "5.. There are a few features (such as ```d5308d8bc```, ```c330f1a67```) that seem to be filled with zeros. These will need to be eliminated.\n",
    "\n",
    "Now let's look at the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "f82085798ab2713c38240f2cf16e148f9dfa9ffa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>dc5a8f1d8</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>4.934300e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "      <td>4.934200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.773670e+04</td>\n",
       "      <td>6.258599e+04</td>\n",
       "      <td>1.036731e+05</td>\n",
       "      <td>6.289726e+04</td>\n",
       "      <td>6.713218e+04</td>\n",
       "      <td>8.083716e+04</td>\n",
       "      <td>6.180889e+04</td>\n",
       "      <td>5.515640e+04</td>\n",
       "      <td>1.406296e+06</td>\n",
       "      <td>8.128503e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193910e+05</td>\n",
       "      <td>1.355955e+05</td>\n",
       "      <td>3.242217e+05</td>\n",
       "      <td>1.437856e+05</td>\n",
       "      <td>9.302367e+04</td>\n",
       "      <td>8.047145e+04</td>\n",
       "      <td>6.076865e+04</td>\n",
       "      <td>1.323210e+05</td>\n",
       "      <td>1.675766e+05</td>\n",
       "      <td>1.282487e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.745165e+06</td>\n",
       "      <td>2.322763e+06</td>\n",
       "      <td>2.586925e+06</td>\n",
       "      <td>2.765913e+06</td>\n",
       "      <td>3.206091e+06</td>\n",
       "      <td>2.845003e+06</td>\n",
       "      <td>2.780109e+06</td>\n",
       "      <td>1.923497e+06</td>\n",
       "      <td>6.872299e+06</td>\n",
       "      <td>2.378914e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.115190e+06</td>\n",
       "      <td>2.598454e+06</td>\n",
       "      <td>3.782996e+06</td>\n",
       "      <td>3.663374e+06</td>\n",
       "      <td>5.041000e+06</td>\n",
       "      <td>2.100210e+06</td>\n",
       "      <td>2.040655e+06</td>\n",
       "      <td>3.592018e+06</td>\n",
       "      <td>3.761816e+06</td>\n",
       "      <td>2.413798e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.504447e+08</td>\n",
       "      <td>2.283295e+08</td>\n",
       "      <td>2.758171e+08</td>\n",
       "      <td>3.972621e+08</td>\n",
       "      <td>4.667591e+08</td>\n",
       "      <td>2.852223e+08</td>\n",
       "      <td>4.863751e+08</td>\n",
       "      <td>2.043290e+08</td>\n",
       "      <td>3.435658e+08</td>\n",
       "      <td>2.310167e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.351692e+08</td>\n",
       "      <td>1.236547e+08</td>\n",
       "      <td>3.793398e+08</td>\n",
       "      <td>4.025480e+08</td>\n",
       "      <td>9.657530e+08</td>\n",
       "      <td>1.680065e+08</td>\n",
       "      <td>2.497913e+08</td>\n",
       "      <td>3.200000e+08</td>\n",
       "      <td>3.186300e+08</td>\n",
       "      <td>2.189782e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 4991 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          48df886f9     0deb4b6a8     34b15f335     a8cb14b00     2f0771a37  \\\n",
       "count  4.934300e+04  4.934300e+04  4.934300e+04  4.934300e+04  4.934300e+04   \n",
       "mean   5.773670e+04  6.258599e+04  1.036731e+05  6.289726e+04  6.713218e+04   \n",
       "std    1.745165e+06  2.322763e+06  2.586925e+06  2.765913e+06  3.206091e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    1.504447e+08  2.283295e+08  2.758171e+08  3.972621e+08  4.667591e+08   \n",
       "\n",
       "          30347e683     d08d1fbe3     6ee66e115     20aa07010     dc5a8f1d8  \\\n",
       "count  4.934300e+04  4.934300e+04  4.934300e+04  4.934300e+04  4.934300e+04   \n",
       "mean   8.083716e+04  6.180889e+04  5.515640e+04  1.406296e+06  8.128503e+04   \n",
       "std    2.845003e+06  2.780109e+06  1.923497e+06  6.872299e+06  2.378914e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    2.852223e+08  4.863751e+08  2.043290e+08  3.435658e+08  2.310167e+08   \n",
       "\n",
       "           ...          3ecc09859     9281abeea     8675bec0b     3a13ed79a  \\\n",
       "count      ...       4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04   \n",
       "mean       ...       1.193910e+05  1.355955e+05  3.242217e+05  1.437856e+05   \n",
       "std        ...       3.115190e+06  2.598454e+06  3.782996e+06  3.663374e+06   \n",
       "min        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%        ...       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max        ...       5.351692e+08  1.236547e+08  3.793398e+08  4.025480e+08   \n",
       "\n",
       "          f677d4d13     71b203550     137efaa80     fb36b89d9     7e293fbaf  \\\n",
       "count  4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04  4.934200e+04   \n",
       "mean   9.302367e+04  8.047145e+04  6.076865e+04  1.323210e+05  1.675766e+05   \n",
       "std    5.041000e+06  2.100210e+06  2.040655e+06  3.592018e+06  3.761816e+06   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    9.657530e+08  1.680065e+08  2.497913e+08  3.200000e+08  3.186300e+08   \n",
       "\n",
       "          9fc776466  \n",
       "count  4.934200e+04  \n",
       "mean   1.282487e+05  \n",
       "std    2.413798e+06  \n",
       "min    0.000000e+00  \n",
       "25%    0.000000e+00  \n",
       "50%    0.000000e+00  \n",
       "75%    0.000000e+00  \n",
       "max    2.189782e+08  \n",
       "\n",
       "[8 rows x 4991 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_describe = test_df.describe()\n",
    "test_df_describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "607ba0f31aa2cbed8de46bc28f331bc43d79d2ae"
   },
   "source": [
    "We see a similar distribution of various statistical aggregates, but by no means the same: seems like there soem substantial distribution shifts between the train and test sets. This will probably be another major concern when it comes to feature selection/engineering. \n",
    "\n",
    "Now let's do some plotting. We'll take a look at, naturally, the ```target``` variable. First, let's make a histogram of its raw value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "3af2b51198404ebccd9ff2294c887e067b1eec16"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(train_df.target.values, bins=100)\n",
    "plt.title('Histogram target counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "x = train_df.iloc[1]\n",
    "plt.hist(x)\n",
    "plt.title('Histogram target counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Log 1+Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f53f3243a4b302458b28c7dbe820c948d82845c"
   },
   "source": [
    "This is a highly skewed distribution, so let's try to re-plot it with with log transform of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0ad44e907a8d1f21c22b9ab43b5886845a21384",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(np.log(1+train_df.target.values), bins=100)\n",
    "plt.title('Histogram target counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Log 1+Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6c451d9726f8aa81d15ab4901bb8310c3bc021ad"
   },
   "source": [
    "As expected, this distribution looks much more, ahem, normal. This is probably one of the main reasons why the metric that we are trying to optimize for this competition is RMSLE - root mean square logarithmic error.\n",
    "\n",
    "Another way of looking at the same distribution is with the help of violinplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f51aad6943161de471d2ab867cf5c3914a902be5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.violinplot(x=np.log(1+train_df.target.values))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfca1cceab212372234861e37f2e6da88df1e2ca"
   },
   "source": [
    "That's ... revealing. And it looks like a fairly nice distribution, albeit still fairly asymetrical.\n",
    "\n",
    "Let's take a look at the statistics of the Log(1+target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b02761bf65df94a8ad5755bc69a621f1c556ff53",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_log_target = train_df[['target']]\n",
    "train_log_target['target'] = np.log(1+train_df['target'].values)\n",
    "train_log_target.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cd47edd4f27b5cceea12fb8cb6f11831bc77e2df"
   },
   "source": [
    "We see that the statistical properties of teh Log(1+Target) distribution are much more amenable.\n",
    "\n",
    "Now let's take a look at columns with constant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e51d35f052a523c63110d09a2768c10f93e2656",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "constant_train = train_df.loc[:, (train_df == train_df.iloc[0]).all()].columns.tolist()\n",
    "constant_test = test_df.loc[:, (test_df == test_df.iloc[0]).all()].columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57cfb56cffc2ec36a2af706e85516c228894a03d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Number of constant columns in the train set:', len(constant_train))\n",
    "print('Number of constant columns in the test set:', len(constant_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "60f162c34418f81f36d4bf234807cec8d1bdb963"
   },
   "source": [
    "So this is interesting: there are 256 constant columns in the train set, but none in the test set. These constant columns are thus most likely an artifact of the way that the train and test sets were constructed, and not necessarily irrelevant in their own right. This is yet another byproduct of having a very small dataset. For most problems it would be useful to take a look at the description of these columns, but in this competition they are anonymized, and thus would not yield any useful information. \n",
    "\n",
    "So let's subset the colums that we'd use to just those that are not constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86f6f85638aa465799c7353d634e8c55c86e3c98",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_use = test_df.columns.tolist()\n",
    "del columns_to_use[0] # Remove 'ID'\n",
    "columns_to_use = [x for x in columns_to_use if x not in constant_train] #Remove all 0 columns\n",
    "len(columns_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba736a41f4bed80f6802106021eae603fba67ea0"
   },
   "source": [
    "So we have the total of 4735 columns to work with. However, as mentioned earlier, most of these columns seem to be filled predominatly with zeros. Let's try to get a better sense of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6802c2048227ddf3f9d24e9be539826bf2cfc838",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe(train_df[columns_to_use].values, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "290b63eb54b58b0b73c045d062fdab9ef79e38f2"
   },
   "source": [
    "If we treat all the train matrix values as if they belonged to a single row vector, we see a huge amount of varience, far exceeding the similar variance for the target variable.\n",
    "\n",
    "Now let's plot it to see how diverse the numerical values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f1b08bb79b018272896aa70e921439234d4834b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(train_df[columns_to_use].values.flatten(), bins=50)\n",
    "plt.title('Histogram all train counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04525960ccf87b1dd67575a9e721a8f2f753cfc2"
   },
   "source": [
    "Wow, not very diverse at all! Most of the values are heavily concentrated around 0. \n",
    "\n",
    "Maybe if we used the log plot things would be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "77c5ca7ae39bad5ef6fcf38cca524dcc859bfa64",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(np.log(train_df[columns_to_use].values.flatten()+1), bins=50)\n",
    "plt.title('Log Histogram all train counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Log value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d9b92f6c8d689ae1519f74413256296d94e4b629"
   },
   "source": [
    "Only marginal improvement - there is a verly small bump close to 15.\n",
    "\n",
    "Can the violin plot help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd9a0dc2c0f2fb417435aa773f1eabfb9cab6fe7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.violinplot(x=np.log(train_df[columns_to_use].values.flatten()+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0e65aa1adfdaf54cd01e30eb0caeb5baee89c598"
   },
   "source": [
    "Not really - the plot looks nicer, but the overall shape is pretty much the same. \n",
    "\n",
    "OK, let's take a look at the distribution of non-zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51afadb9102a0f83b118f501283815a1c1507b10",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_nz = np.log(train_df[columns_to_use].values.flatten()+1)\n",
    "train_nz = train_nz[np.nonzero(train_nz)]\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(train_nz, bins=50)\n",
    "plt.title('Log Histogram nonzero train counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Log value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "345d146725ea4ed5b0b3c72ea3d1ad4202d9d3be",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.violinplot(x=train_nz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1df44618757f67c08f52dee55f493cdabc20699d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe(train_nz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a1b840fcc8aa6ea7d230d7dbddf77a57b5051d3"
   },
   "source": [
    "OK, that's much more interesting. \n",
    "\n",
    "Let's do the same thing with the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c60d61837eb6c6bb312fd836b78a49e4625d0f7a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_nz = np.log(test_df[columns_to_use].values.flatten()+1)\n",
    "test_nz = test_nz[np.nonzero(test_nz)]\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(test_nz, bins=50)\n",
    "plt.title('Log Histogram nonzero test counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Log value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4d863ea1e9e68baeddfc4489229eb94e7e0146a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.violinplot(x=test_nz)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "637771c7fa255c4774129436ec14e9ca64d0a129",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe(test_nz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18662f10c3848ddd528ec999ed0c0edc7b3907bb"
   },
   "source": [
    "Again, we see that these distributions look similar, but they are definitely not the same. \n",
    "\n",
    "Now let's take a closer look at the shape and content of the train data. We want to get a better numerical grasp of the true extent of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e5bd84c83fc7e0088845525a96aff4296a7a459",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[columns_to_use].values.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32ac9171b22fdee9a516d60c5f835a030c0a699b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "((train_df[columns_to_use].values.flatten())==0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e08287b75a1dab72e340acc6df8cd55b3118db9f"
   },
   "source": [
    "So as we suspected, almost 97% of all values in the train dataframe are zeros. That looks pretty sparse to me, but let's see how much variation is there between different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb6ddba0e89053d0b079ba352a7f95c1326a9e2f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_zeros = pd.DataFrame({'Percentile':((train_df[columns_to_use].values)==0).mean(axis=0),\n",
    "                           'Column' : columns_to_use})\n",
    "train_zeros.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46e189cd4d7843ef6321ee661bf939b1785d6c61",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe(train_zeros.Percentile.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f52eceace2727ec15a6d4f9407d4f1cdef7cfaf"
   },
   "source": [
    "So it seems that the vast majority of columns have 95+ percent of zeros in them. Let's see how would that look on a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5591ebb27983fafdf44195b94ec511b25c853fea",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(train_zeros.Percentile.values, bins=50)\n",
    "plt.title('Histogram percentage zeros train counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f550f099d87c605b39bfb318ddcd8ab79c333cc8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe(np.log(train_df[columns_to_use].values+1), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3fc8a6673c4b51c8d901fde3002f4b8574546fdd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe(test_df[columns_to_use].values, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e0f39c628fd1844f737458e83afcd1a084e03b7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe(np.log(test_df[columns_to_use].values+1), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16c9ee191a40019ad759e2c9e6ed856445b0f68a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_zeros = pd.DataFrame({'Percentile':(np.log(1+test_df[columns_to_use].values)==0).mean(axis=0),\n",
    "                           'Column' : columns_to_use})\n",
    "test_zeros.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1b4a9611dce80572534d03dc34a493f49a507ac2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe(test_zeros.Percentile.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2cc60c600724fe1b40cc2cac7f92f70e92be2d01"
   },
   "source": [
    "OK, let's try to do some modeling. We'll start with a simple LighGBM regression, and see if that yields any results. First, let's set our target variable to be the log of 1 + target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a721f3f2a2f3cdd43be57bfc9ef6f478a6bdb24",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.log(1+train_df.target.values)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e0c0eaf845202260680e9f9be07a5bc4da2bec1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a439fd6c7e20de1d61ba4da4b701229fd96ebb2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = lgb.Dataset(train_df[columns_to_use],y ,feature_name = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7902addc1b7d349074a82e94692fdc25cb462af",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt', \n",
    "          'objective': 'regression', \n",
    "          'metric': 'rmse', \n",
    "          'learning_rate': 0.01, \n",
    "          'num_leaves': 100, \n",
    "          'feature_fraction': 0.4, \n",
    "          'bagging_fraction': 0.6, \n",
    "          'max_depth': 5, \n",
    "          'min_child_weight': 10}\n",
    "\n",
    "\n",
    "clf = lgb.train(params,\n",
    "        train,\n",
    "        num_boost_round = 400,\n",
    "        verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0015b95cb9dfdb97dd14ad3c1f9851a2324d36f1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = clf.predict(test_df[columns_to_use])\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0cb3e73535f9ebd8249f1522f234da9e9153062",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission.target = np.exp(preds)-1\n",
    "sample_submission.to_csv('simple_lgbm_1.csv', index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "052f815b8df425cbd5bee7b84584b8fa4b6f9848"
   },
   "source": [
    "Well, that's great - we made a prediction on the test set, and saved it to a file, which we were able to submit to the competition. Unfortunately, there was no way to tell how this model would perform on the unseen data. (This submission scored 1.53 on Public Leaderboard.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37677ac9717b572c193ea02e3bed91d416047785",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr_splits = 5\n",
    "random_state = 1054\n",
    "\n",
    "y_oof = np.zeros((y.shape[0]))\n",
    "total_preds = 0\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=nr_splits, shuffle=True, random_state=random_state)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(y)):\n",
    "    print('Fitting fold', i+1, 'out of', nr_splits)\n",
    "    X_train, X_val  = train_df[columns_to_use].iloc[train_index], train_df[columns_to_use].iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    train = lgb.Dataset(X_train,y_train ,feature_name = \"auto\")\n",
    "    val = lgb.Dataset(X_val ,y_val ,feature_name = \"auto\")\n",
    "    clf = lgb.train(params,train,num_boost_round = 400,verbose_eval=True)\n",
    "    \n",
    "    total_preds += clf.predict(test_df[columns_to_use])/nr_splits\n",
    "    pred_oof = clf.predict(X_val)\n",
    "    y_oof[val_index] = pred_oof\n",
    "    print('Fold error', np.sqrt(mean_squared_error(y_val, pred_oof)))\n",
    "\n",
    "print('Total error', np.sqrt(mean_squared_error(y, y_oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a703120049c8dcb63290784923efa2e254e83200",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_depth'] = 4\n",
    "\n",
    "y_oof_2 = np.zeros((y.shape[0]))\n",
    "total_preds_2 = 0\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=nr_splits, shuffle=True, random_state=random_state)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(y)):\n",
    "    print('Fitting fold', i+1, 'out of', nr_splits)\n",
    "    X_train, X_val  = train_df[columns_to_use].iloc[train_index], train_df[columns_to_use].iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    train = lgb.Dataset(X_train,y_train ,feature_name = \"auto\")\n",
    "    val = lgb.Dataset(X_val ,y_val ,feature_name = \"auto\")\n",
    "    clf = lgb.train(params,train,num_boost_round = 400,verbose_eval=True)\n",
    "    \n",
    "    total_preds_2 += clf.predict(test_df[columns_to_use])/nr_splits\n",
    "    pred_oof = clf.predict(X_val)\n",
    "    y_oof_2[val_index] = pred_oof\n",
    "    print('Fold error', np.sqrt(mean_squared_error(y_val, pred_oof)))\n",
    "\n",
    "print('Total error', np.sqrt(mean_squared_error(y, y_oof_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c482d29c852c7b4b8238977caccb87e0bb03cca",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_depth'] = 6\n",
    "\n",
    "y_oof_3 = np.zeros((y.shape[0]))\n",
    "total_preds_3 = 0\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=nr_splits, shuffle=True, random_state=random_state)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(y)):\n",
    "    print('Fitting fold', i+1, 'out of', nr_splits)\n",
    "    X_train, X_val  = train_df[columns_to_use].iloc[train_index], train_df[columns_to_use].iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    train = lgb.Dataset(X_train,y_train ,feature_name = \"auto\")\n",
    "    val = lgb.Dataset(X_val ,y_val ,feature_name = \"auto\")\n",
    "    clf = lgb.train(params,train,num_boost_round = 400,verbose_eval=True)\n",
    "    \n",
    "    total_preds_3 += clf.predict(test_df[columns_to_use])/nr_splits\n",
    "    pred_oof = clf.predict(X_val)\n",
    "    y_oof_3[val_index] = pred_oof\n",
    "    print('Fold error', np.sqrt(mean_squared_error(y_val, pred_oof)))\n",
    "\n",
    "print('Total error', np.sqrt(mean_squared_error(y, y_oof_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5d273fa90735e413b93d6c7aa82bea5f5a0a785",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_depth'] = 7\n",
    "\n",
    "y_oof_4 = np.zeros((y.shape[0]))\n",
    "total_preds_4 = 0\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=nr_splits, shuffle=True, random_state=random_state)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(y)):\n",
    "    print('Fitting fold', i+1, 'out of', nr_splits)\n",
    "    X_train, X_val  = train_df[columns_to_use].iloc[train_index], train_df[columns_to_use].iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    train = lgb.Dataset(X_train,y_train ,feature_name = \"auto\")\n",
    "    val = lgb.Dataset(X_val ,y_val ,feature_name = \"auto\")\n",
    "    clf = lgb.train(params,train,num_boost_round = 400,verbose_eval=True)\n",
    "    \n",
    "    total_preds_4 += clf.predict(test_df[columns_to_use])/nr_splits\n",
    "    pred_oof = clf.predict(X_val)\n",
    "    y_oof_4[val_index] = pred_oof\n",
    "    print('Fold error', np.sqrt(mean_squared_error(y_val, pred_oof)))\n",
    "\n",
    "print('Total error', np.sqrt(mean_squared_error(y, y_oof_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86d23a397707a1b4be1c8ab8424e28f8601355ae",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_depth'] = 8\n",
    "\n",
    "y_oof_5 = np.zeros((y.shape[0]))\n",
    "total_preds_5 = 0\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=nr_splits, shuffle=True, random_state=random_state)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(y)):\n",
    "    print('Fitting fold', i+1, 'out of', nr_splits)\n",
    "    X_train, X_val  = train_df[columns_to_use].iloc[train_index], train_df[columns_to_use].iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    train = lgb.Dataset(X_train,y_train ,feature_name = \"auto\")\n",
    "    val = lgb.Dataset(X_val ,y_val ,feature_name = \"auto\")\n",
    "    clf = lgb.train(params,train,num_boost_round = 400,verbose_eval=True)\n",
    "    \n",
    "    total_preds_5 += clf.predict(test_df[columns_to_use])/nr_splits\n",
    "    pred_oof = clf.predict(X_val)\n",
    "    y_oof_5[val_index] = pred_oof\n",
    "    print('Fold error', np.sqrt(mean_squared_error(y_val, pred_oof)))\n",
    "\n",
    "print('Total error', np.sqrt(mean_squared_error(y, y_oof_5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5298997028e742c0ccf5a94ac33918de2830f55f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_depth'] = 10\n",
    "\n",
    "y_oof_6 = np.zeros((y.shape[0]))\n",
    "total_preds_6 = 0\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=nr_splits, shuffle=True, random_state=random_state)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(y)):\n",
    "    print('Fitting fold', i+1, 'out of', nr_splits)\n",
    "    X_train, X_val  = train_df[columns_to_use].iloc[train_index], train_df[columns_to_use].iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    train = lgb.Dataset(X_train,y_train ,feature_name = \"auto\")\n",
    "    val = lgb.Dataset(X_val ,y_val ,feature_name = \"auto\")\n",
    "    clf = lgb.train(params,train,num_boost_round = 400,verbose_eval=True)\n",
    "    \n",
    "    total_preds_6 += clf.predict(test_df[columns_to_use])/nr_splits\n",
    "    pred_oof = clf.predict(X_val)\n",
    "    y_oof_6[val_index] = pred_oof\n",
    "    print('Fold error', np.sqrt(mean_squared_error(y_val, pred_oof)))\n",
    "\n",
    "print('Total error', np.sqrt(mean_squared_error(y, y_oof_6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f530d9c894fbe9fa5217a9558a075fcb2e79cd01",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params['max_depth'] = 12\n",
    "\n",
    "y_oof_7 = np.zeros((y.shape[0]))\n",
    "total_preds_7 = 0\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=nr_splits, shuffle=True, random_state=random_state)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(y)):\n",
    "    print('Fitting fold', i+1, 'out of', nr_splits)\n",
    "    X_train, X_val  = train_df[columns_to_use].iloc[train_index], train_df[columns_to_use].iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    train = lgb.Dataset(X_train,y_train ,feature_name = \"auto\")\n",
    "    val = lgb.Dataset(X_val ,y_val ,feature_name = \"auto\")\n",
    "    clf = lgb.train(params,train,num_boost_round = 400,verbose_eval=True)\n",
    "    \n",
    "    total_preds_7 += clf.predict(test_df[columns_to_use])/nr_splits\n",
    "    pred_oof = clf.predict(X_val)\n",
    "    y_oof_7[val_index] = pred_oof\n",
    "    print('Fold error', np.sqrt(mean_squared_error(y_val, pred_oof)))\n",
    "\n",
    "print('Total error', np.sqrt(mean_squared_error(y, y_oof_7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89a304ca994091d8b5c8b040039c4789adc99f96",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Total error', np.sqrt(mean_squared_error(y, 1.4*(1.6*y_oof_7-0.6*y_oof_6)-0.4*y_oof_5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "14e907aa1d6e4629fd28ab610124293fc7dc9a06",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Total error', np.sqrt(mean_squared_error(y, -0.5*y_oof-0.5*y_oof_2-y_oof_3\n",
    "                                                +3*y_oof_4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4419aa6462b7e129ce809fd246993e604bc040ff",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Total error', np.sqrt(mean_squared_error(y, 0.75*(1.4*(1.6*y_oof_7-0.6*y_oof_6)-0.4*y_oof_5)+\n",
    "                                                0.25*(-0.5*y_oof-0.5*y_oof_2-y_oof_3\n",
    "                                                +3*y_oof_4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c049caa0a6090a0d00beccac7436e42e36a1ea3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_preds = (0.75*(1.4*(1.6*total_preds_7-0.6*total_preds_6)-0.4*total_preds_5)+\n",
    "                                                0.25*(-0.5*total_preds-0.5*total_preds_2-total_preds_3\n",
    "                                                +3*total_preds_4))\n",
    "#sub_preds = (-0.5*total_preds-0.5*total_preds_2-total_preds_3+3*total_preds_4)\n",
    "sample_submission.target = np.exp(sub_preds)-1\n",
    "sample_submission.to_csv('blended_submission_2.csv', index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36f9f3165e4b24d5dcdc1e7632503df9cb0b2e99",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'objective': 'reg:linear', \n",
    "          'eval_metric': 'rmse',\n",
    "          'eta': 0.01,\n",
    "          'max_depth': 10, \n",
    "          'subsample': 0.6, \n",
    "          'colsample_bytree': 0.6,\n",
    "          'alpha':0.001,\n",
    "          'random_state': 42, \n",
    "          'silent': True}\n",
    "\n",
    "y_oof_8 = np.zeros((y.shape[0]))\n",
    "total_preds_8 = 0\n",
    "\n",
    "dtest = xgb.DMatrix(test_df[columns_to_use])\n",
    "\n",
    "kf = KFold(n_splits=nr_splits, shuffle=True, random_state=random_state)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(y)):\n",
    "    print('Fitting fold', i+1, 'out of', nr_splits)\n",
    "    X_train, X_val  = train_df[columns_to_use].iloc[train_index], train_df[columns_to_use].iloc[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    \n",
    "    train = xgb.DMatrix(X_train, y_train)\n",
    "    val = xgb.DMatrix(X_val, y_val)\n",
    "    \n",
    "    watchlist = [(train, 'train'), (val, 'val')]\n",
    "    \n",
    "    clf = xgb.train(params, train, 1000, watchlist, \n",
    "                          maximize=False, early_stopping_rounds = 60, verbose_eval=100)\n",
    "\n",
    "    \n",
    "    total_preds_8 += clf.predict(dtest, ntree_limit=clf.best_ntree_limit)/nr_splits\n",
    "    pred_oof = clf.predict(val, ntree_limit=clf.best_ntree_limit)\n",
    "    y_oof_8[val_index] = pred_oof\n",
    "    print('Fold error', np.sqrt(mean_squared_error(y_val, pred_oof)))\n",
    "\n",
    "print('Total error', np.sqrt(mean_squared_error(y, y_oof_8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a73f20311cfd1b06a67739fb7bb58eb58064aad"
   },
   "source": [
    "### To do:\n",
    "\n",
    "1. Meke some plots\n",
    "2. Build a few models\n",
    "3. Do feature importance analysis\n",
    "\n",
    "## To be continued ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "897fde43949fdf12f697ee56e2b740895f98bc6e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Total error', np.sqrt(mean_squared_error(y, 0.7*(0.75*(1.4*(1.6*y_oof_7-0.6*y_oof_6)-0.4*y_oof_5)+\n",
    "                                                0.25*(-0.5*y_oof-0.5*y_oof_2-y_oof_3\n",
    "                                                +3*y_oof_4))+0.3*y_oof_8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "593154b715fe4a4a049b25867389e0a7d096d995",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_preds = (0.7*(0.75*(1.4*(1.6*total_preds_7-0.6*total_preds_6)-0.4*total_preds_5)+\n",
    "                                                0.25*(-0.5*total_preds-0.5*total_preds_2-total_preds_3\n",
    "                                                +3*total_preds_4))+0.3*total_preds_8)\n",
    "#sub_preds = (-0.5*total_preds-0.5*total_preds_2-total_preds_3+3*total_preds_4)\n",
    "sample_submission.target = np.exp(sub_preds)-1\n",
    "sample_submission.to_csv('blended_submission_3.csv', index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "301a141c884fbceff9fbddc523ed37b39bdfdec4",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6a7ac73a0398a9e3b96d7652413e3f5a3859baab",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b541a112c2b08f38a618d413bc57c5fb6fd638f8",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0c4e3d3a796bcda2f409477d4237655d345ffe5e",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7cc4e71988540ecf2b62d5dca5e4edd21f0ec398",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
